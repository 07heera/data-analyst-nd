{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5 Analysing Data\n",
    "\n",
    "Exploring data using the MongoDB aggregation framework: initial analysis and additional cleaning.\n",
    "\n",
    "e.g. Twitter Data Set"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Twitter Data Schema\n",
    "\n",
    "{\n",
    "    \"_id\" : ObjectId(\"4380oueut34.\"),\n",
    "    \"text\" : \"Hello\",\n",
    "    \"entities\" : {\n",
    "        \"user_mentions\" : [\n",
    "            {\n",
    "                \"screen_name\" : \"somebody_else\",\n",
    "            }\n",
    "        ],\n",
    "        \"urls\" : [ ],\n",
    "        \"hashtags\" : [ ]\n",
    "    },\n",
    "    \"user\" : {\n",
    "        \"friends_count\" : 544,\n",
    "        \"screen_name\" : \"somebody\",\n",
    "        \"followers_count\" : 100,\n",
    "        ...\n",
    "    },\n",
    "    ...\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples of questions: Understand behaviour of users and networks involved.\n",
    "\n",
    "Aggregation Framework provides a powerful tool for analysing data.\n",
    "E.g.: Determine which user has produced the most tweets. \n",
    "Process:\n",
    "1. Group tweets by user\n",
    "2. Count each user's tweets\n",
    "3. Sort into descending order (of number of tweets)\n",
    "4. Select user at the top (the one with most tweets)\n",
    "\n",
    "Aggregation queries in MongoDB issued using 'aggregate', done using a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pprint\n",
    "\n",
    "client = MongoClient(\"mongodb://localhost:27017\")\n",
    "db = client.twitter\n",
    "\n",
    "def most_tweets():\n",
    "    # Issue aggregation query\n",
    "    result = db.tweets.aggregate([\n",
    "            # For user subdocument, I want the screen name field\n",
    "            # \"$user.screen_name\" don't make it a string. Not an operator.\n",
    "            # Want value of user.screen_name\n",
    "            { \"$group\" : { \"_id\" : \"$user.screen_name\",\n",
    "                          # Accumulator operator \"$sum\": For all docs that have the same value for _id,\n",
    "                          # Increment count by 1.\n",
    "                           \"count\" : { \"$sum\" : 1 } } },\n",
    "            # Sort docs passed into this stage (output of \"$group\")\n",
    "            # based on the count in descending order\n",
    "            { \"$sort\" : { \"count\" : -1} } ])\n",
    "    return result\n",
    "\n",
    "if __name__ = \"__main__\":\n",
    "    result = most_tweets()\n",
    "    pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# in Terminal\n",
    "# pipe command into less to see top of results produced\n",
    "python file_name | less\n",
    "\n",
    "<u'ok' : 1.0,\n",
    " u'result': [{u'_id': u'behcolin', u'count': 8},\n",
    "             ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation Pipline \n",
    "\n",
    "* diagram\n",
    "* e.g. \"\\$group\" -> \"\\$sort\" \n",
    "* Collection fed into group stage. Finds tweets per user and accumulates them.\n",
    "* Depending on which operator is used in a given stage, stage may be reshaping data. Collection of tweets have dozens of fields, putting through \"\\$group\" stage turns it into data with 2 fields.\n",
    "* Use aggregation operators to produce stages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "The tweets in our twitter collection have a field called \"source\". This field describes the application\n",
    "that was used to create the tweet. Following the examples for using the $group operator, your task is \n",
    "to modify the 'make-pipeline' function to identify most used applications for creating tweets. \n",
    "As a check on your query, 'web' is listed as the most frequently used application.\n",
    "'Ubertwitter' is the second most used. The number of counts should be stored in a field named 'count'\n",
    "(see the assertion at the end of the script).\n",
    "\n",
    "Please modify only the 'make_pipeline' function so that it creates and returns an aggregation pipeline\n",
    "that can be passed to the MongoDB aggregate function. As in our examples in this lesson, the aggregation \n",
    "pipeline should be a list of one or more dictionary objects. \n",
    "Please review the lesson examples if you are unsure of the syntax.\n",
    "\n",
    "Your code will be run against a MongoDB instance that we have provided. \n",
    "If you want to run this code locally on your machine, you have to install MongoDB, \n",
    "download and insert the dataset.\n",
    "For instructions related to MongoDB setup and datasets please see Course Materials.\n",
    "\n",
    "Please note that the dataset you are using here is a smaller version of the twitter dataset \n",
    "used in examples in this lesson. \n",
    "If you attempt some of the same queries that we looked at in the lesson examples,\n",
    "your results will be different.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_db(db_name):\n",
    "    from pymongo import MongoClient\n",
    "    client = MongoClient('localhost:27017')\n",
    "    db = client[db_name]\n",
    "    return db\n",
    "\n",
    "def make_pipeline():\n",
    "    # complete the aggregation pipeline\n",
    "    pipeline = [{\"$group\" : {\"source\" : \"$source\",\n",
    "                             \"count\" : {\"$sum\" : 1} } },\n",
    "                {\"$sort\" : {\"count\" : -1} } ]\n",
    "    return pipeline\n",
    "\n",
    "def tweet_sources(db, pipeline):\n",
    "    return [doc for doc in db.tweets.aggregate(pipeline)]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    db = get_db('twitter')\n",
    "    pipeline = make_pipeline()\n",
    "    result = tweet_sources(db, pipeline)\n",
    "    import pprint\n",
    "    pprint.pprint(result[0])\n",
    "    assert result[0] == {u'count': 868, u'_id': u'web'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation Operators: An overview\n",
    "### 1. Project\n",
    "Reshaping data\n",
    "e.g. Selecting which fields you are interested in"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
